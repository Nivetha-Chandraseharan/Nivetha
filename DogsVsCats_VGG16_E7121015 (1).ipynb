{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8BpRY3jL7bi",
        "outputId": "d5a93648-4404-4d4f-9bd9-99a3f897a291"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HabJ1G4kMInk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30626d65-8628-4fd6-9003-4e46ca34a728"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "58900480/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "vgg_model=VGG16(include_top=False,weights='imagenet',input_shape=(224,224,3),classes=2,classifier_activation='sigmoid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9ipZwrnNLWC",
        "outputId": "45c3fdc4-e26e-43ca-b3ca-96a990a4da2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "vgg_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_x64JjqlOH1C"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gsXWZ0lNPp3",
        "outputId": "8826200f-4d8a-422b-a3bd-8be6c75f5f80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6404 images belonging to 2 classes.\n",
            "Found 1601 images belonging to 2 classes.\n",
            "Found 2023 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train=ImageDataGenerator(rescale=1./255,\n",
        "                            rotation_range=5,\n",
        "                            zoom_range=.2,\n",
        "                            horizontal_flip=True,validation_split=0.2)\n",
        "test=ImageDataGenerator(rescale=1./255)\n",
        "train_data=train.flow_from_directory('/content/gdrive/MyDrive/dataset/datasetweek2/DogVsCat/training_set',color_mode='rgb',\n",
        "                                        target_size=(224,224),\n",
        "                                        batch_size=1,\n",
        "                                        class_mode='binary',\n",
        "                                        shuffle=True,subset=\"training\")\n",
        "val_data=train.flow_from_directory('/content/gdrive/MyDrive/dataset/datasetweek2/DogVsCat/training_set',color_mode='rgb',\n",
        "                                        target_size=(224,224),\n",
        "                                        batch_size=1,\n",
        "                                        class_mode='binary',\n",
        "                                        shuffle=True,subset=\"validation\")\n",
        "test_data=test.flow_from_directory('/content/gdrive/MyDrive/dataset/datasetweek2/DogVsCat/test_set',color_mode='rgb',\n",
        "                                        target_size=(224,224),\n",
        "                                        batch_size=1,\n",
        "                                        class_mode='binary',\n",
        "                                        shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3_GErrQPWRb"
      },
      "outputs": [],
      "source": [
        "for layer in vgg_model.layers:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGj98PL3Pm_i"
      },
      "outputs": [],
      "source": [
        "from keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.applications.vgg19 import VGG19, preprocess_input\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "x = Flatten()(vgg_model.output)\n",
        "x=Dense(4096,activation='relu')(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAjYAQEyP3_G"
      },
      "outputs": [],
      "source": [
        "\n",
        "prediction=Dense(1, activation='sigmoid')(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "be2YiMs7QBBD"
      },
      "outputs": [],
      "source": [
        "model = Model(inputs=vgg_model.input, outputs=prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ck1aBhhhQn2k",
        "outputId": "c5f18b6d-cc38-45e5-bf5d-cd606c46b46a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 4096)              102764544 \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 4097      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 117,483,329\n",
            "Trainable params: 102,768,641\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5T-YVnQQ5BG"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "  loss='binary_crossentropy',\n",
        "  optimizer=\"adam\",\n",
        "  metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LAWSKmg6Q-oC"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stop=EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=5)\n",
        "#Early stopping to avoid overfitting of model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qN9hTtpVRBjO",
        "outputId": "ef17115f-5083-4121-b186-11b6d98e8d08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        }
      ],
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "checkpoint = ModelCheckpoint(\"vgg16_1.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atoHjx2bRL8y",
        "outputId": "1b449ea7-d0eb-4768-e855-c59a2fef0934"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "200/200 [==============================] - ETA: 0s - loss: 5.9882 - accuracy: 0.6150"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200/200 [==============================] - 56s 276ms/step - loss: 5.9882 - accuracy: 0.6150 - val_loss: 1.2447 - val_accuracy: 0.7708\n",
            "Epoch 2/10\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.2978 - accuracy: 0.7550"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200/200 [==============================] - 42s 210ms/step - loss: 1.2978 - accuracy: 0.7550 - val_loss: 1.3329 - val_accuracy: 0.6352\n",
            "Epoch 3/10\n",
            "199/200 [============================>.] - ETA: 0s - loss: 0.6513 - accuracy: 0.7387"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200/200 [==============================] - 46s 230ms/step - loss: 0.6602 - accuracy: 0.7350 - val_loss: 0.5265 - val_accuracy: 0.7801\n",
            "Epoch 4/10\n",
            "199/200 [============================>.] - ETA: 0s - loss: 0.5681 - accuracy: 0.7990"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200/200 [==============================] - 46s 228ms/step - loss: 0.5721 - accuracy: 0.7950 - val_loss: 0.3744 - val_accuracy: 0.8370\n",
            "Epoch 5/10\n",
            "199/200 [============================>.] - ETA: 0s - loss: 0.3709 - accuracy: 0.8543"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200/200 [==============================] - 47s 234ms/step - loss: 0.3693 - accuracy: 0.8550 - val_loss: 0.2888 - val_accuracy: 0.8745\n",
            "Epoch 6/10\n",
            "199/200 [============================>.] - ETA: 0s - loss: 0.3457 - accuracy: 0.8543"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200/200 [==============================] - 47s 235ms/step - loss: 0.3445 - accuracy: 0.8550 - val_loss: 0.2968 - val_accuracy: 0.8751\n",
            "Epoch 7/10\n",
            "199/200 [============================>.] - ETA: 0s - loss: 0.3307 - accuracy: 0.8442"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200/200 [==============================] - 47s 234ms/step - loss: 0.3321 - accuracy: 0.8450 - val_loss: 0.2592 - val_accuracy: 0.8851\n",
            "Epoch 8/10\n",
            "199/200 [============================>.] - ETA: 0s - loss: 0.3127 - accuracy: 0.8794"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200/200 [==============================] - 48s 242ms/step - loss: 0.3112 - accuracy: 0.8800 - val_loss: 0.3277 - val_accuracy: 0.8570\n",
            "Epoch 9/10\n",
            "199/200 [============================>.] - ETA: 0s - loss: 0.4598 - accuracy: 0.7889"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200/200 [==============================] - 48s 241ms/step - loss: 0.4598 - accuracy: 0.7900 - val_loss: 0.3180 - val_accuracy: 0.8595\n",
            "Epoch 10/10\n",
            "199/200 [============================>.] - ETA: 0s - loss: 0.3231 - accuracy: 0.8492"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 50s 250ms/step - loss: 0.3386 - accuracy: 0.8450 - val_loss: 0.2642 - val_accuracy: 0.8826\n"
          ]
        }
      ],
      "source": [
        "# fit the model\n",
        "history = model.fit(\n",
        " train_data,\n",
        "  \n",
        "  validation_data=val_data,\n",
        "  epochs=10,steps_per_epoch=len(train_data)//32,\n",
        "  callbacks=[early_stop,checkpoint],\n",
        "  batch_size=32,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laGNgfFORtcL"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
        "import numpy as np\n",
        "#predict\n",
        "y_pred=model.predict(test_data)\n",
        "y_pred=np.argmax(y_pred,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(test_data.classes,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iojqR9KAUDtZ",
        "outputId": "2e3c5ca9-b08d-4da4-8502-9be3b807ad88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1011,    0],\n",
              "       [1012,    0]])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKMAZlA0R4gH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afea6201-bd3f-4d98-9783-c8df0399cb29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model to disk\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model.save(\"/content/drive/MyDrive/VGG_dogsVscats.h5\")\n",
        "print(\"Saved model to disk\")\n",
        "model.save_weights(\"/content/drive/MyDrive/VGG_dogsVscats.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qgH77eS5fMCb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}